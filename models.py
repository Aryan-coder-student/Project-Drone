# -*- coding: utf-8 -*-
"""models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IgNQTG6xCzdjru16CU58pS9RnwkLuGrU
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer, KNNImputer
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import xgboost as xgb
import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv('city_day.csv')

print("Dataset Shape:", df.shape)

print("\nColumns:", df.columns.tolist())
print("\nMissing values per column:")
print(df.isnull().sum())
print(f"\nTotal missing values: {df.isnull().sum().sum()}")

data_nulls = (df.apply(lambda x: x.isnull().value_counts()).T[True]/len(df)*100).reset_index(name='count')
fig = plt.figure(figsize=(12,6))
fig = sns.barplot(data_nulls, x="index", y="count")
fig.set_title('Null Values in the Data', fontsize=30)
fig.set_xlabel('features', fontsize=12)
fig.set_xticklabels(fig.get_xticklabels(), rotation=45)
fig.set_ylabel('% of null values', fontsize=12)
fig.bar_label(fig.containers[0], fmt='%.1f')
plt.tight_layout()

print("\nAQI_Bucket value counts:")
print(df['AQI_Bucket'].value_counts())
aqi_order = ['Good', 'Satisfactory', 'Moderate', 'Poor', 'Very Poor', 'Severe']

city_counts = df['City'].value_counts()
plt.figure(figsize=(10, 8))
bars = plt.barh(city_counts.index, city_counts.values)
plt.title('Number of Samples by City', fontsize=16, pad=20)
plt.xlabel('Count', fontsize=12)
plt.ylabel('City', fontsize=12)

for bar in bars:
    width = bar.get_width()
    plt.text(width + 0.5, bar.get_y() + bar.get_height()/2.,
             f'{int(width)}', ha='left', va='center')

plt.tight_layout()
plt.show()

class_dist = df['AQI_Bucket'].value_counts()

print("Class Distribution Statistics:")
print(f"Total samples: {len(df)}")
print(f"Number of classes: {len(class_dist)}")
print(f"Most common class: {class_dist.index[0]} ({class_dist.values[0]} samples)")
print(f"Least common class: {class_dist.index[-1]} ({class_dist.values[-1]} samples)")
print(f"Imbalance ratio: {class_dist.values[0]/class_dist.values[-1]:.2f}")

plt.figure(figsize=(10, 8))
plt.pie(class_dist.values, labels=class_dist.index, autopct='%1.1f%%', startangle=90)
plt.title('Distribution of AQI Bucket Classes', fontsize=16, pad=20)
plt.axis('equal')
plt.tight_layout()
plt.show()

# 3. Correlation Analysis
def plot_correlation_analysis(df):
    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()

    if len(numerical_cols) < 2:
        print("Not enough numerical columns for correlation analysis")
        return
    corr_matrix = df[numerical_cols].corr()

    plt.figure(figsize=(12, 10))
    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='RdBu_r',
                center=0, square=True, linewidths=0.5)
    plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig('correlation_matrix.png', dpi=300, bbox_inches='tight')
    plt.show()

    corr_matrix_abs = df[numerical_cols].corr().abs()
    upper_tri = corr_matrix_abs.where(np.triu(np.ones_like(corr_matrix_abs, dtype=bool), k=1))
    high_corr = [(column, upper_tri[column].idxmax(), upper_tri[column].max())
                 for column in upper_tri.columns if upper_tri[column].max() > 0.7]

    if high_corr:
        print("\nHighly correlated features (|r| > 0.7):")
        for col1, col2, corr in high_corr:
            print(f"{col1} - {col2}: {corr:.3f}")

plot_correlation_analysis(df)

# 4. Feature Distribution Analysis
def plot_feature_distributions(df):
    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()

    if not numerical_cols:
        print("No numerical columns for distribution analysis")
        return

    n_cols = 3
    n_rows = (len(numerical_cols) + n_cols - 1) // n_cols

    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))
    fig.suptitle('Feature Distributions', fontsize=16, fontweight='bold')
    if n_rows > 1:
        axes = axes.flatten()
    else:
        axes = [axes]

    for i, col in enumerate(numerical_cols):
        if i < len(axes):

            sns.histplot(df[col].dropna(), kde=True, ax=axes[i])
            axes[i].set_title(f'{col} Distribution')
            axes[i].set_xlabel(col)
            stats_text = f'Mean: {df[col].mean():.2f}\nStd: {df[col].std():.2f}\nMissing: {df[col].isnull().sum()}'
            axes[i].text(0.95, 0.95, stats_text, transform=axes[i].transAxes,
                        verticalalignment='top', horizontalalignment='right',
                        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
    for j in range(i+1, len(axes)):
        axes[j].set_visible(False)

    plt.tight_layout()
    plt.savefig('feature_distributions.png', dpi=300, bbox_inches='tight')
    plt.show()

plot_feature_distributions(df)

# 6. Multivariate Analysis - Pairplot of key features
def plot_multivariate_analysis(df):
    key_features = ['PM2.5', 'PM10', 'NO2', 'CO', 'SO2', 'O3']
    key_features = [f for f in key_features if f in df.columns]

    if len(key_features) < 3:
        print("Not enough features for multivariate analysis")
        return
    if 'AQI_Bucket' in df.columns:
        sample_df = df[key_features + ['AQI_Bucket']].dropna()
        if len(sample_df) > 1000:
            sample_df = sample_df.sample(1000, random_state=42)
        g = sns.pairplot(sample_df, hue='AQI_Bucket', diag_kind='kde',
                        palette={'Good': 'green', 'Satisfactory': 'lightgreen',
                                'Moderate': 'yellow', 'Poor': 'orange',
                                'Very Poor': 'red', 'Severe': 'darkred'})
        g.fig.suptitle('Pairplot of Key Features by AQI Category', y=1.02, fontsize=16, fontweight='bold')
        plt.savefig('feature_pairplot.png', dpi=300, bbox_inches='tight')
        plt.show()
    else:
        sample_df = df[key_features].dropna()
        if len(sample_df) > 1000:
            sample_df = sample_df.sample(1000, random_state=42)

        g = sns.pairplot(sample_df, diag_kind='kde')
        g.fig.suptitle('Pairplot of Key Features', y=1.02, fontsize=16, fontweight='bold')
        plt.savefig('feature_pairplot.png', dpi=300, bbox_inches='tight')
        plt.show()

plot_multivariate_analysis(df)

# Preprocessing
def preprocess_data(df):
    df_processed = df.copy() #copy of df

    df_processed['AQI_Bucket'] = pd.Categorical(df_processed['AQI_Bucket'], categories=aqi_order,ordered=True)


    le = LabelEncoder()
    df_processed['AQI_Bucket_encoded'] = le.fit_transform(df_processed['AQI_Bucket'].astype(str))


    pollutant_cols = ['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3',
                     'Benzene', 'Toluene', 'Xylene']

    df_for_analysis = df_processed.dropna(subset=['AQI_Bucket'])

    return df_processed, df_for_analysis, pollutant_cols

df_processed, df_for_analysis, pollutant_cols = preprocess_data(df)

def analyze_feature_importance(df, pollutant_cols):

    temp_df = df.dropna(subset=['AQI_Bucket_encoded'] + pollutant_cols, how='any')

    if len(temp_df) == 0:
        print("Not enough complete cases for feature importance analysis.")
        return None, None

    X_temp = temp_df[pollutant_cols]
    y_temp = temp_df['AQI_Bucket_encoded']


    rf = RandomForestClassifier(n_estimators=100, random_state=42)
    rf.fit(X_temp, y_temp)

    # Get feature importances
    importances = rf.feature_importances_
    feature_importance_df = pd.DataFrame({
        'Feature': pollutant_cols,
        'Importance': importances
    }).sort_values('Importance', ascending=False)

    print("Feature Importance for Predicting AQI_Bucket:")
    print(feature_importance_df)

    # Plot feature importance
    plt.figure(figsize=(10, 6))
    sns.barplot(x='Importance', y='Feature', data=feature_importance_df)
    plt.title('Feature Importance for AQI Prediction')
    plt.tight_layout()
    plt.show()

    return rf, feature_importance_df

rf_model, feature_importance_df = analyze_feature_importance(df_for_analysis, pollutant_cols)

"""# **Missing Values (Imputation)**"""

# MICE imputation
def impute_missing_values(df, pollutant_cols):
    print("Starting MICE imputation...")

    df_imputed = df.copy()

    mice_imputer = IterativeImputer(estimator=RandomForestRegressor(n_estimators=10, random_state=42),max_iter=10,random_state=42,initial_strategy='mean')

    df_imputed[pollutant_cols] = mice_imputer.fit_transform(df_imputed[pollutant_cols])

    print("MICE imputation completed.")
    return df_imputed
    # Apply MICE imputation to the entire dataset
df_imputed = impute_missing_values(df_processed, pollutant_cols)

def prepare_training_data(df_imputed):
    train_df = df_imputed.dropna(subset=['AQI_Bucket'])
    X = train_df[pollutant_cols]
    y = train_df['AQI_Bucket_encoded']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    return X_train_scaled, X_test_scaled, y_train, y_test, scaler

X_train, X_test, y_train, y_test, scaler = prepare_training_data(df_imputed)

"""# XGBoost"""

def train_and_evaluate_model(X_train, X_test, y_train, y_test):
    print("Training XGBoost model...")

    xgb_model = xgb.XGBClassifier(
        n_estimators=100,
        max_depth=6,
        learning_rate=0.1,
        random_state=42,
        use_label_encoder=False,
        eval_metric='mlogloss'
    )

    xgb_model.fit(X_train, y_train)


    y_pred = xgb_model.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    print(f"Model Accuracy: {accuracy:.4f}")
    print(classification_report(y_test, y_pred, target_names=aqi_order))

    # Confusion matrix
    plt.figure(figsize=(10, 8))
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=aqi_order, yticklabels=aqi_order)
    plt.title('Confusion Matrix')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.xticks(rotation=45)
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.show()

    return xgb_model

xgb_model = train_and_evaluate_model(X_train, X_test, y_train, y_test)

from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV
from sklearn.utils.class_weight import compute_class_weight
import xgboost as xgb
import lightgbm as lgb
import warnings
warnings.filterwarnings('ignore')

print("Shape of training data:", X_train.shape)
print("Shape of testing data:", X_test.shape)

print("\nClass distribution in training set:")
print(pd.Series(y_train).value_counts())
print("\nClass distribution in testing set:")
print(pd.Series(y_test).value_counts())

classes = np.unique(y_train)
class_weights = compute_class_weight('balanced', classes=classes, y=y_train)
class_weight_dict = dict(zip(classes, class_weights))
print("Class weights:", class_weight_dict)

"""# **LGBM**"""

#LightGBM Model
lgb_model = lgb.LGBMClassifier(n_estimators=300,learning_rate=0.05,num_leaves=31,class_weight='balanced',random_state=42,n_jobs=-1)

lgb_model.fit(X_train, y_train)
lgb_pred = lgb_model.predict(X_test)
lgb_accuracy = accuracy_score(y_test, lgb_pred)
print(f"LightGBM Accuracy: {lgb_accuracy:.4f}")

"""# **RF**"""

#Random Forest
rf_model = RandomForestClassifier(n_estimators=300,max_depth=15,min_samples_split=5,min_samples_leaf=2,class_weight=class_weight_dict,random_state=42,n_jobs=-1)
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test)
rf_accuracy = accuracy_score(y_test, rf_pred)
print(f"Random Forest Accuracy: {rf_accuracy:.4f}")

"""# **Ensemble**"""

#Create an Ensemble Model

ensemble_model = VotingClassifier(
    estimators=[('xgb', xgb_model),('lgb', lgb_model),('rf', rf_model)],voting='soft',n_jobs=-1)

ensemble_model.fit(X_train, y_train)
ensemble_pred = ensemble_model.predict(X_test)
ensemble_accuracy = accuracy_score(y_test, ensemble_pred)
print(f"Ensemble Model Accuracy: {ensemble_accuracy:.4f}")

"""# **Comparison**"""

# Define the models with their parameters (but don't fit them yet)
models = {
    'XGBoost': xgb.XGBClassifier(
        n_estimators=100,
        max_depth=6,
        learning_rate=0.1,
        random_state=42,
        use_label_encoder=False,
        eval_metric='mlogloss'
    ),
    'LightGBM': lgb.LGBMClassifier(
        n_estimators=100,
        learning_rate=0.05,
        num_leaves=31,
        random_state=42
    ),
    'Random Forest': RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        random_state=42
    )
}

# First, perform cross-validation on unfitted models
model_comparison = []
for name, model in models.items():
    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)
    model_comparison.append({
        'Model': name,
        'CV Mean Accuracy': cv_scores.mean(),
        'CV Std': cv_scores.std()
    })

# Now fit the models on the full training data
fitted_models = {}
for name, model in models.items():
    fitted_model = model.fit(X_train, y_train)
    fitted_models[name] = fitted_model
    # Add test accuracy to the comparison
    for item in model_comparison:
        if item['Model'] == name:
            item['Test Accuracy'] = accuracy_score(y_test, fitted_model.predict(X_test))

# Create the ensemble model using the fitted models
ensemble_model = VotingClassifier(
    estimators=[
        ('xgb', fitted_models['XGBoost']),
        ('lgb', fitted_models['LightGBM']),
        ('rf', fitted_models['Random Forest'])
    ],
    voting='soft'
)

# Fit the ensemble model (it doesn't need training data as it uses pre-fitted estimators)
ensemble_model.fit(X_train, y_train)  # This will still work

# Add ensemble to the comparison
ensemble_pred = ensemble_model.predict(X_test)
ensemble_accuracy = accuracy_score(y_test, ensemble_pred)

model_comparison.append({
    'Model': 'Ensemble',
    'CV Mean Accuracy': np.mean([item['CV Mean Accuracy'] for item in model_comparison]),  # Approximate
    'CV Std': np.mean([item['CV Std'] for item in model_comparison]),  # Approximate
    'Test Accuracy': ensemble_accuracy
})

model_comparison_df = pd.DataFrame(model_comparison).sort_values('Test Accuracy', ascending=False)
print(model_comparison_df)

best_model_name = model_comparison_df.iloc[0]['Model']
if best_model_name == 'Ensemble':
    best_model = ensemble_model
else:
    best_model = fitted_models[best_model_name]

print(f"\nBest Model: {best_model_name}")
y_pred = best_model.predict(X_test)

plt.figure(figsize=(10, 8))
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=aqi_order, yticklabels=aqi_order)
plt.title(f'Confusion Matrix - {best_model_name}')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.tight_layout()
plt.savefig('confusion_matrix.png')
plt.show()

# Save model
import joblib
joblib.dump(best_model, 'best_aqi_model.pkl')
joblib.dump(scaler, 'scaler.pkl')
joblib.dump(pollutant_cols, 'pollutant_columns.pkl')

print(f"\n model ({best_model_name}) saved successfully!")